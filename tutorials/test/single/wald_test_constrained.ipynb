{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diffxpy.api as de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect confounding occurs frequently in differential expression assays, often if biological replicates cannot be spread across conditions: This is often the case with animals or patients. Perfect confounding implies that the corresponding design matrix is not full rank and the model underdetermined. This can be circumvented by certain tricks (where replicates are modeled as the interaction of condition and and a replicate index per condition) which essentially regress repplicates to reference replicates. We believe that this is firstly undesirable as the condition coefficients depend on the identity of the reference replicates and accordingly on the ordering of the replicates, which has no experiental meaning and is purely a result of sample labels. Secondly, such tricks may be hard to come up with in hard cases. Here, we show how one can solve both problems by constraining parameterse in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more examples refer to the constraint tutorial in batchglm (~/tutorials/nb_glm_constraints.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have 4 biological replicates (animals, patients, cell culture replicates etc.) in a treatment experiment: 2 in each condition (treated, untreated). Accordingly, there is perfect confounding at this level. We circumvent this by constraining the biological replicate coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define design matrices for simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we built a one-hot encoded design matrix of discrete covariated (biological replicate and treatment) as a numpy array cells x parameters of model. We will later use this design matrix both for the location and scale model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 1. 1.]\n",
      " [1. 0. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ncells = 2000\n",
    "dmat = np.zeros([ncells, 6])\n",
    "dmat[:,0] = 1\n",
    "dmat[:500,1] = 1 # bio rep 1\n",
    "dmat[500:1000,2] = 1 # bio rep 2\n",
    "dmat[1000:1500,3] = 1 # bio rep 3\n",
    "dmat[1500:2000,4] = 1 # bio rep 4\n",
    "dmat[1000:2000,5] = 1 # condition effect\n",
    "print(np.unique(dmat, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate data using the design matrix defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchglm.api.models.nb_glm import Simulator\n",
    "\n",
    "sim = Simulator(num_features=100)\n",
    "sim.parse_dmat_loc(dmat = dmat)\n",
    "sim.parse_dmat_scale(dmat = dmat)\n",
    "mu=1; phi=0.1\n",
    "sim.generate_params(rand_fn_loc=lambda size: mu + scipy.stats.truncnorm.rvs(-mu / phi, np.infty, scale=phi, size=size))\n",
    "sim.generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design matrix for estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build design matrix is pandas data frame in which the column names are coefficient names and the rows are cells in the same order as in your data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient_names = ['intercept', 'bio1', 'bio2', 'bio3', 'bio4', 'treatment1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmat_est = pd.DataFrame(data=dmat, columns=coefficient_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the diffxpy design matrix builder / formatting function de.test.design_matrix() to build a design matrix that can be input into diffxpy from the pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmat_est_loc = de.test.design_matrix(dmat = dmat_est)\n",
    "dmat_est_scale = de.test.design_matrix(dmat = dmat_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build constraints based on sets of parameters that have to sum to zero. Each of these constraints is enforced by binding one of these parameters to the rest of the set. Such a constraint is encoded by assigning a 1 to each parameter in the set and a -1 to to the dependent parameter. The constraints have to be ordered so that they can be iteratively applied from top to bottom and so that all independent parameters (1s) are defined at each stage: A dependent parameter may depend on another dependent parameter if the other dependent parameter was defined in a constrained that lies before the current constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., -1.,  1.,  0.],\n",
       "       [ 0., -1.,  1.,  1.,  1.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints_loc = np.zeros([2, dmat_est_loc.dims['design_params']])\n",
    "# Constraint 0: Account for perfect confouding at biological replicate and treatment level \n",
    "# by constraining biological replicate coefficients not to produce mean effects across conditions.\n",
    "constraints_loc[0,3] = -1\n",
    "constraints_loc[0,4:5] = 1\n",
    "# Constraint 1: Account for fact that first level of biological replicates was not absorbed into offset.\n",
    "constraints_loc[1,1] = -1\n",
    "constraints_loc[1,2:5] = 1\n",
    "\n",
    "constraints_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same constraints also for the scale model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_scale = constraints_loc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model fitting and differential expression test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we perform a single-coefficient Wald test on the treatment effect, accounting for all confounders by using the above defined constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating model...\n",
      "Using closed-form MLE initialization for mean\n",
      "Should train mu: False\n",
      "Using closed-form MME initialization for dispersion\n",
      "Should train r: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david.fischer/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/Users/david.fischer/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/Users/david.fischer/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/Users/david.fischer/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Users/david.fischer/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Users/david.fischer/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Users/david.fischer/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training strategy:\n",
      "[{'convergence_criteria': 't_test',\n",
      "  'learning_rate': 0.01,\n",
      "  'loss_window_size': 10,\n",
      "  'optim_algo': 'ADAM',\n",
      "  'stop_at_loss_change': 0.25,\n",
      "  'use_batching': False}]\n",
      "Beginning with training sequence #1\n",
      "Training sequence #1 complete\n",
      "Estimating model ready\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"batchglm\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"diffxpy\").setLevel(logging.INFO)\n",
    "\n",
    "import diffxpy.api as de\n",
    "\n",
    "test = de.test.wald(\n",
    "    data = sim.X, # count data\n",
    "    dmat_loc = dmat_est_loc.data_vars['design'],\n",
    "    dmat_scale = dmat_est_scale.data_vars['design'],\n",
    "    constraints_loc = constraints_loc,\n",
    "    constraints_scale = constraints_scale,\n",
    "    coef_to_test=[\"treatment1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f438358e57945f292633406623fa8f0",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
